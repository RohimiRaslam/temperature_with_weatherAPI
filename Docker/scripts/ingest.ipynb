{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from pandas import json_normalize\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine , inspect\n",
    "import psycopg2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('weather_api_key')\n",
    "base_url = 'http://api.weatherapi.com/v1'\n",
    "history_url = base_url + \"/history.json\"\n",
    "\n",
    "db_name = os.getenv('db_name')\n",
    "user = os.getenv('user')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "port = os.getenv('port')\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{db_name}')\n",
    "\n",
    "capitals = [\n",
    "    \"Johor Bahru\", \n",
    "    \"Alor Setar\", \n",
    "    \"Kota Bharu\", \n",
    "    \"Melaka\", \n",
    "    \"Seremban\", \n",
    "    \"Kuantan\", \n",
    "    \"George Town\", \n",
    "    \"Ipoh\", \n",
    "    \"Kangar\", \n",
    "    \"Kota Kinabalu\", \n",
    "    \"Kuching\", \n",
    "    \"Shah Alam\", \n",
    "    \"Kuala Terengganu\",\n",
    "    \"Kuala Lumpur\" \n",
    "]\n",
    "dates_string = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "dates = [(datetime.now() - timedelta(day)) for day in range(1,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_history():\n",
    "    for capital in capitals:    \n",
    "        for date in dates_string:\n",
    "            params = {'key': api_key, 'q': capital , 'dt': date}\n",
    "            r = requests.get(history_url , params=params).json()\n",
    "            df = pd.json_normalize(r)\n",
    "            hours_df = json_normalize(df['forecast.forecastday'][0][0]['hour'])\n",
    "\n",
    "            hours_df['location'] = df['location.name']\n",
    "            hours_df['region'] = df['location.region']\n",
    "            hours_df['country'] = df['location.country']\n",
    "            hours_df['date'] = hours_df['time'].dt.date\n",
    "            hours_df = hours_df.ffill(axis=0)\n",
    "            capital = re.sub(r'\\s+', '_', capital)\n",
    "            return hours_df\n",
    "            \n",
    "            \n",
    "            # hours_df.to_sql(f\"{capital}_hourly\" , if_exists='append' , index=False , con=engine)\n",
    "\n",
    "hourly = get_hourly_history()\n",
    "hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_string = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(0,9)]\n",
    "dict_empty = {}\n",
    "df = pd.DataFrame(dict_empty)\n",
    "\n",
    "for capital in capitals:    \n",
    "    for date in dates_string:\n",
    "                params = {'key': api_key, 'q': capital , 'dt': date}\n",
    "                r = requests.get(history_url , params=params)\n",
    "                response = r.json()\n",
    "                raw_data = pd.json_normalize(response)\n",
    "                hours_df = pd.json_normalize(raw_data['forecast.forecastday'][0][0]['hour'])\n",
    "                hours_df['location'] = raw_data['location.name']\n",
    "                hours_df = hours_df.ffill(axis=0)\n",
    "                df = pd.concat([df , hours_df] , axis=0)\n",
    "df.head(3)\n",
    "\n",
    "\n",
    "        # hours_df['location'] = df['location.name']\n",
    "        # hours_df['region'] = df['location.region']\n",
    "        # hours_df['country'] = df['location.country']\n",
    "        # hours_df['date'] = pd.to_datetime(hours_df['time']).dt.date\n",
    "        # hours_df = hours_df.ffill(axis=0)\n",
    "\n",
    "# hours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_string = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "dict_empty = {}\n",
    "daily_df = pd.DataFrame(dict_empty)\n",
    "\n",
    "for capital in capitals:\n",
    "    for date in dates_string:\n",
    "        params = {'key': api_key, 'q': capital , 'dt': date}\n",
    "        response = requests.get(history_url , params=params)\n",
    "        day_history_data = response.json()\n",
    "        day_raw_data = pd.json_normalize(day_history_data)\n",
    "\n",
    "        days_df = pd.json_normalize(day_raw_data['forecast.forecastday'][0][0]['day'])\n",
    "        days_df['date'] = day_raw_data['forecast.forecastday'][0][0]['date']\n",
    "        days_df['location'] = day_raw_data['location.name']\n",
    "        days_df = days_df.rename(columns={\"condition.text\":\"condition\"} , inplace=False).drop(columns=['condition.icon','condition.code'] , axis=1)\n",
    "        capital = re.sub(r'\\s+', '_', capital)\n",
    "        with engine.begin() as connection:\n",
    "            days_df.to_sql(f\"{capital}_daily\" , if_exists='append' , index=False , con=connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2025-01-09',\n",
       " '2025-01-08',\n",
       " '2025-01-07',\n",
       " '2025-01-06',\n",
       " '2025-01-05',\n",
       " '2025-01-04',\n",
       " '2025-01-03',\n",
       " '2025-01-02',\n",
       " '2025-01-01']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_string = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(0,9)]\n",
    "dates_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_epoch</th>\n",
       "      <th>time</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>temp_f</th>\n",
       "      <th>is_day</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>wind_kph</th>\n",
       "      <th>wind_degree</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>pressure_mb</th>\n",
       "      <th>...</th>\n",
       "      <th>chance_of_snow</th>\n",
       "      <th>vis_km</th>\n",
       "      <th>vis_miles</th>\n",
       "      <th>gust_mph</th>\n",
       "      <th>gust_kph</th>\n",
       "      <th>uv</th>\n",
       "      <th>condition.text</th>\n",
       "      <th>condition.icon</th>\n",
       "      <th>condition.code</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1736352000</td>\n",
       "      <td>2025-01-09 00:00</td>\n",
       "      <td>25.2</td>\n",
       "      <td>77.3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/116.png</td>\n",
       "      <td>1003</td>\n",
       "      <td>Johor Bahru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1736355600</td>\n",
       "      <td>2025-01-09 01:00</td>\n",
       "      <td>25.1</td>\n",
       "      <td>77.1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.4</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/113.png</td>\n",
       "      <td>1000</td>\n",
       "      <td>Johor Bahru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1736359200</td>\n",
       "      <td>2025-01-09 02:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/113.png</td>\n",
       "      <td>1000</td>\n",
       "      <td>Johor Bahru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1736362800</td>\n",
       "      <td>2025-01-09 03:00</td>\n",
       "      <td>24.9</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/116.png</td>\n",
       "      <td>1003</td>\n",
       "      <td>Johor Bahru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1736366400</td>\n",
       "      <td>2025-01-09 04:00</td>\n",
       "      <td>24.7</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>11</td>\n",
       "      <td>NNE</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/113.png</td>\n",
       "      <td>1000</td>\n",
       "      <td>Johor Bahru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1735729200</td>\n",
       "      <td>2025-01-01 19:00</td>\n",
       "      <td>25.1</td>\n",
       "      <td>77.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>290</td>\n",
       "      <td>WNW</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Light rain shower</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/day/353.png</td>\n",
       "      <td>1240</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1735732800</td>\n",
       "      <td>2025-01-01 20:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>322</td>\n",
       "      <td>NW</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Patchy rain possible</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/176.png</td>\n",
       "      <td>1063</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1735736400</td>\n",
       "      <td>2025-01-01 21:00</td>\n",
       "      <td>23.8</td>\n",
       "      <td>74.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>348</td>\n",
       "      <td>NNW</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Patchy rain possible</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/176.png</td>\n",
       "      <td>1063</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1735740000</td>\n",
       "      <td>2025-01-01 22:00</td>\n",
       "      <td>23.6</td>\n",
       "      <td>74.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>356</td>\n",
       "      <td>N</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/116.png</td>\n",
       "      <td>1003</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1735743600</td>\n",
       "      <td>2025-01-01 23:00</td>\n",
       "      <td>23.1</td>\n",
       "      <td>73.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>28</td>\n",
       "      <td>NNE</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Patchy rain possible</td>\n",
       "      <td>//cdn.weatherapi.com/weather/64x64/night/176.png</td>\n",
       "      <td>1063</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3024 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_epoch              time  temp_c  temp_f  is_day  wind_mph  wind_kph  \\\n",
       "0   1736352000  2025-01-09 00:00    25.2    77.3       0       8.7      14.0   \n",
       "1   1736355600  2025-01-09 01:00    25.1    77.1       0       8.9      14.4   \n",
       "2   1736359200  2025-01-09 02:00    25.0    77.0       0       8.5      13.7   \n",
       "3   1736362800  2025-01-09 03:00    24.9    76.8       0       8.9      14.4   \n",
       "4   1736366400  2025-01-09 04:00    24.7    76.5       0       8.5      13.7   \n",
       "..         ...               ...     ...     ...     ...       ...       ...   \n",
       "19  1735729200  2025-01-01 19:00    25.1    77.1       1       2.7       4.3   \n",
       "20  1735732800  2025-01-01 20:00    24.0    75.3       0       1.8       2.9   \n",
       "21  1735736400  2025-01-01 21:00    23.8    74.9       0       1.6       2.5   \n",
       "22  1735740000  2025-01-01 22:00    23.6    74.4       0       2.0       3.2   \n",
       "23  1735743600  2025-01-01 23:00    23.1    73.6       0       2.0       3.2   \n",
       "\n",
       "    wind_degree wind_dir  pressure_mb  ...  chance_of_snow  vis_km  vis_miles  \\\n",
       "0             7        N       1011.0  ...               0    10.0        6.0   \n",
       "1             9        N       1011.0  ...               0    10.0        6.0   \n",
       "2            10        N       1011.0  ...               0    10.0        6.0   \n",
       "3            10        N       1010.0  ...               0    10.0        6.0   \n",
       "4            11      NNE       1009.0  ...               0    10.0        6.0   \n",
       "..          ...      ...          ...  ...             ...     ...        ...   \n",
       "19          290      WNW       1008.0  ...               0    10.0        6.0   \n",
       "20          322       NW       1009.0  ...               0    10.0        6.0   \n",
       "21          348      NNW       1010.0  ...               0    10.0        6.0   \n",
       "22          356        N       1011.0  ...               0    10.0        6.0   \n",
       "23           28      NNE       1011.0  ...               0    10.0        6.0   \n",
       "\n",
       "    gust_mph  gust_kph   uv        condition.text  \\\n",
       "0       14.1      22.7  0.0         Partly cloudy   \n",
       "1       14.0      22.5  0.0                 Clear   \n",
       "2       13.1      21.1  0.0                 Clear   \n",
       "3       13.8      22.1  0.0         Partly cloudy   \n",
       "4       13.2      21.2  0.0                 Clear   \n",
       "..       ...       ...  ...                   ...   \n",
       "19       4.9       7.8  6.0     Light rain shower   \n",
       "20       3.5       5.6  0.0  Patchy rain possible   \n",
       "21       3.1       4.9  0.0  Patchy rain possible   \n",
       "22       4.0       6.5  0.0         Partly cloudy   \n",
       "23       4.2       6.8  0.0  Patchy rain possible   \n",
       "\n",
       "                                      condition.icon  condition.code  \\\n",
       "0   //cdn.weatherapi.com/weather/64x64/night/116.png            1003   \n",
       "1   //cdn.weatherapi.com/weather/64x64/night/113.png            1000   \n",
       "2   //cdn.weatherapi.com/weather/64x64/night/113.png            1000   \n",
       "3   //cdn.weatherapi.com/weather/64x64/night/116.png            1003   \n",
       "4   //cdn.weatherapi.com/weather/64x64/night/113.png            1000   \n",
       "..                                               ...             ...   \n",
       "19    //cdn.weatherapi.com/weather/64x64/day/353.png            1240   \n",
       "20  //cdn.weatherapi.com/weather/64x64/night/176.png            1063   \n",
       "21  //cdn.weatherapi.com/weather/64x64/night/176.png            1063   \n",
       "22  //cdn.weatherapi.com/weather/64x64/night/116.png            1003   \n",
       "23  //cdn.weatherapi.com/weather/64x64/night/176.png            1063   \n",
       "\n",
       "        location  \n",
       "0    Johor Bahru  \n",
       "1    Johor Bahru  \n",
       "2    Johor Bahru  \n",
       "3    Johor Bahru  \n",
       "4    Johor Bahru  \n",
       "..           ...  \n",
       "19  Kuala Lumpur  \n",
       "20  Kuala Lumpur  \n",
       "21  Kuala Lumpur  \n",
       "22  Kuala Lumpur  \n",
       "23  Kuala Lumpur  \n",
       "\n",
       "[3024 rows x 37 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_string = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(0,9)]\n",
    "dict_empty = {}\n",
    "df = pd.DataFrame(dict_empty)\n",
    "\n",
    "for capital in capitals:    \n",
    "    for date in dates_string:\n",
    "                params = {'key': api_key, 'q': capital , 'dt': date}\n",
    "                r = requests.get(history_url , params=params)\n",
    "                response = r.json()\n",
    "                raw_data = pd.json_normalize(response)\n",
    "                hours_df = pd.json_normalize(raw_data['forecast.forecastday'][0][0]['hour'])\n",
    "                hours_df['location'] = raw_data['location.name']\n",
    "                hours_df = hours_df.ffill(axis=0)\n",
    "                df = pd.concat([df , hours_df] , axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B\n",
      "0  7   9\n",
      "1  8  10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame pertama\n",
    "df1 = pd.DataFrame({})\n",
    "\n",
    "# DataFrame kedua\n",
    "df2 = pd.DataFrame({\n",
    "    'A': [7, 8],\n",
    "    'B': [9, 10]\n",
    "})\n",
    "\n",
    "# Menambahkan df2 ke df1\n",
    "df_combined = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "print(df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_history():\n",
    "    history_url = base_url + \"/history.json\"\n",
    "    dates = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "    hourly_dict = {}\n",
    "    \n",
    "    for date in dates:\n",
    "        for capital in capitals:\n",
    "            params = {\"key\": api_key, \"q\": capital, \"dt\": date}\n",
    "            try:\n",
    "                response = requests.get(history_url, params=params)\n",
    "                if response.status_code == 200:\n",
    "                    history_data = response.json()\n",
    "                    df = pd.json_normalize(history_data['forecast']['forecastday'][0]['hour'])\n",
    "                    # hourly = history_data['forecast']['forecastday'][0]['hour']\n",
    "                    \n",
    "                    # hourly_dict = {}\n",
    "                    \n",
    "                    # for d in hourly:\n",
    "                    #     for key, value in d.items():\n",
    "                    #         if key in hourly_dict:\n",
    "                    #             hourly_dict[key].append(value)\n",
    "                    #         else:\n",
    "                    #             hourly_dict[key] = [value]\n",
    "                    # df = pd.DataFrame(hourly_dict)\n",
    "                    # print(df.head())\n",
    "                    table_name = f\"{capital}_{date}\"\n",
    "                    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "                    # inspector = inspect(engine)\n",
    "                    # if inspector.has_table(table_name):\n",
    "                    #     print(f\"{table_name} is already existed, skipping...\")\n",
    "                    #     continue\n",
    "                    # else:\n",
    "                    #     df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "                else:\n",
    "                    print(f\"Error: Received unexpected status code {response.status_code} on {capital}\")\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "get_hourly_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "def get_hourly_history():\n",
    "    folder_path = 'hourly_data'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    history_url = base_url + \"/history.json\"\n",
    "\n",
    "    dates = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "    hourly_dict = {}\n",
    "    \n",
    "    for date in dates[:1]:\n",
    "        for capital in capitals[:1]:\n",
    "            params = {\"key\": api_key, \"q\": capital, \"dt\": date}\n",
    "            try:\n",
    "                response = requests.get(history_url, params=params)\n",
    "                if response.status_code == 200:\n",
    "                    history_data = response.json()\n",
    "\n",
    "                    hourly = history_data['forecast']['forecastday'][0]['hour']\n",
    "                    \n",
    "                    # hourly_dict = {}\n",
    "                    \n",
    "                    for d in hourly:\n",
    "                        for key, value in d.items():\n",
    "                            if key in hourly_dict:\n",
    "                                hourly_dict[key].append(value)\n",
    "                            else:\n",
    "                                hourly_dict[key] = [value]\n",
    "                    df = pd.DataFrame(hourly_dict)\n",
    "                    df = pd.json_normalize(df)\n",
    "                    print(df.head())\n",
    "\n",
    "                    # file_name = f\"{capital}_{date}\"\n",
    "                    # file_path = os.path.join(folder_path , file_name)\n",
    "\n",
    "                    # if os.path.exists(file_path):\n",
    "                    #     print(f\"{file_path} is already existed, skipping...\")\n",
    "                    #     continue\n",
    "                    # else:\n",
    "                    #     df.to_csv(file_path , index=False, header=True, encoding=None)\n",
    "                else:\n",
    "                    print(f\"Error: Received unexpected status code {response.status_code} on {capital}\")\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "get_hourly_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2025, 1, 22)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.bash_operator import BashOperator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection parameters\n",
    "conn = psycopg2.connect(\n",
    "    dbname = os.getenv('db_name'), \n",
    "    user = os.getenv('user'), \n",
    "    password = os.getenv('password'), \n",
    "    host = os.getenv('host'), \n",
    "    port = os.getenv('port')\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute a query to list tables\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all table names\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Print the table names\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from pandas import json_normalize\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine , inspect\n",
    "import psycopg2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('weather_api_key')\n",
    "base_url = 'http://api.weatherapi.com/v1'\n",
    "history_url = base_url + \"/history.json\"\n",
    "\n",
    "db_name = os.getenv('db_name')\n",
    "user = os.getenv('user')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "port = os.getenv('port')\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{db_name}')\n",
    "\n",
    "capitals = [\n",
    "    \"johor bahru\", \n",
    "    \"alor setar\", \n",
    "    \"kota bharu\", \n",
    "    \"melaka\", \n",
    "    \"seremban\", \n",
    "    \"kuantan\", \n",
    "    \"george town\", \n",
    "    \"ipoh\", \n",
    "    \"kangar\", \n",
    "    \"kota kinabalu\", \n",
    "    \"kuching\", \n",
    "    \"shah alam\", \n",
    "    \"kuala terengganu\",\n",
    "    \"kuala lumpur\" \n",
    "]\n",
    "\n",
    "dates = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "\n",
    "def get_daily_history():\n",
    "    for capital in capitals:\n",
    "        for date in dates:\n",
    "            params = {'key': api_key, 'q': capital , 'dt': date}\n",
    "            response = requests.get(history_url , params=params)\n",
    "            day_history_data = response.json()\n",
    "            day_raw_data = pd.json_normalize(day_history_data)\n",
    "\n",
    "            days_df = pd.json_normalize(day_raw_data['forecast.forecastday'][0][0]['day'])\n",
    "            days_df['date'] = day_raw_data['forecast.forecastday'][0][0]['date']\n",
    "            days_df['location'] = day_raw_data['location.name']\n",
    "            days_df = days_df.rename(columns={\"condition.text\":\"condition\"} , inplace=False).drop(columns=['condition.icon','condition.code'] , axis=1)\n",
    "            # display(days_df)\n",
    "\n",
    "            capital = re.sub(r'\\s+', '_', capital)\n",
    "            with engine.begin() as connection:\n",
    "                \n",
    "                # days_df.to_sql(f\"{capital}_daily\" , if_exists='fail' , index=False , con=connection)\n",
    "\n",
    "get_daily_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = 'http://api.weatherapi.com/v1'\n",
    "history_url = base_url + \"/history.json\"\n",
    "params = {'key': '98078c8de2274791b03161315240410', 'q': 'kuching' , 'dt': '2025-01-15'}\n",
    "r = requests.get(history_url, params=params)\n",
    "\n",
    "\n",
    "\n",
    "# r.json()['forecast.forecastday'][0][0]['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['location', 'forecast'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = r.json()\n",
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['forecastday'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['forecast'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['date', 'date_epoch', 'day', 'astro', 'hour'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['forecast']['forecastday'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-01-15'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['forecast']['forecastday'][0]['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'maxtemp_c': 31.1,\n",
       " 'maxtemp_f': 88.1,\n",
       " 'mintemp_c': 22.0,\n",
       " 'mintemp_f': 71.7,\n",
       " 'avgtemp_c': 25.3,\n",
       " 'avgtemp_f': 77.5,\n",
       " 'maxwind_mph': 4.0,\n",
       " 'maxwind_kph': 6.5,\n",
       " 'totalprecip_mm': 2.38,\n",
       " 'totalprecip_in': 0.09,\n",
       " 'totalsnow_cm': 0.0,\n",
       " 'avgvis_km': 6.2,\n",
       " 'avgvis_miles': 3.0,\n",
       " 'avghumidity': 86,\n",
       " 'daily_will_it_rain': 1,\n",
       " 'daily_chance_of_rain': 100,\n",
       " 'daily_will_it_snow': 0,\n",
       " 'daily_chance_of_snow': 0,\n",
       " 'condition': {'text': 'Light rain shower',\n",
       "  'icon': '//cdn.weatherapi.com/weather/64x64/day/353.png',\n",
       "  'code': 1240},\n",
       " 'uv': 7.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['forecast']['forecastday'][0]['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop table ipoh_daily_staging;\n",
    "\n",
    "CREATE TABLE ipoh_daily_staging AS\n",
    "WITH \n",
    "duplicate_cte AS (SELECT * , ROW_NUMBER() OVER(PARTITION BY date) AS row_num FROM ipoh_daily),\n",
    "corrected_cte AS (SELECT * FROM duplicate_cte where row_num = 1),\n",
    "selected_columns AS (SELECT location , date ,maxtemp_c , mintemp_c , avgtemp_c , maxwind_kph , avghumidity , condition FROM corrected_cte)\n",
    "SELECT * FROM selected_columns;\n",
    "\n",
    "\n",
    "\n",
    "SELECT * FROM ipoh_daily_staging;\n",
    "\n",
    "\n",
    "\n",
    "SELECT * FROM ipoh_daily;\n",
    "\n",
    "# ==================================\n",
    "\n",
    "-- staging table\n",
    "DROP TABLE ipoh_hourly_staging;\n",
    "\n",
    "CREATE TABLE ipoh_hourly_staging AS\n",
    "WITH \n",
    "rownum_cte AS (SELECT * , ROW_NUMBER() OVER(PARTITION BY time) AS duplicate_row FROM ipoh_hourly),\n",
    "removeduplicate_cte AS (SELECT * FROM rownum_cte WHERE duplicate_row = 1),\n",
    "selectedcolumn_cte AS (SELECT location , time , temp_c , feelslike_c , is_day , wind_kph , humidity , cloud , heatindex_c , dewpoint_c , uv , \"condition.text\" AS condition FROM removeduplicate_cte)\n",
    "SELECT *\n",
    "FROM selectedcolumn_cte;\n",
    "\n",
    "select * from ipoh_hourly_staging\n",
    "\n",
    "-- split date and time columns\n",
    "ALTER TABLE ipoh_hourly_staging\n",
    "ADD COLUMN date_part date,\n",
    "ADD COLUMN time_part time;\n",
    "\n",
    "\n",
    "UPDATE ipoh_hourly_staging\n",
    "SET date_part = (time::timestamp)::date , time_part = (time::timestamp)::time;\n",
    "\n",
    "-- time when it was the hottest of the day\n",
    "CREATE TABLE ipoh_hourly_hottest AS\n",
    "WITH time_cte AS(\n",
    "SELECT \n",
    "    t1.location,\n",
    "\tt1.date_part AS date, \n",
    "    t1.time_part AS time, \n",
    "    t1.temp_c AS max_temp\n",
    "FROM ipoh_hourly_staging t1\n",
    "WHERE t1.temp_c = (SELECT MAX(t2.temp_c) FROM ipoh_hourly_staging t2 WHERE t2.date_part = t1.date_part))\n",
    "SELECT *\n",
    "FROM time_cte;\n",
    "\n",
    "SELECT * FROM ipoh_hourly_hottest ORDER BY date;\n",
    "\n",
    "# --=========================================================================================================================================================\n",
    "\n",
    "# drop table ipoh_hourly_hottest\n",
    "\n",
    "\n",
    "# drop table ipoh_hourly_hottest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from pandas import json_normalize\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine , inspect\n",
    "import psycopg2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres : airflow : airflow : localhost : 5432\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "db_name = os.getenv('db_name')\n",
    "user = os.getenv('user')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "port = os.getenv('port')\n",
    "\n",
    "print(db_name , ':' , user , ':' , password , ':' , host , ':' , port )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to PostgreSQL DB successful\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def test_connection():\n",
    "    # Replace these values with your actual database credentials\n",
    "    db_name = os.getenv('db_name')\n",
    "    user = os.getenv('user')\n",
    "    password = os.getenv('password')\n",
    "    host = os.getenv('host')\n",
    "    port = os.getenv('port')\n",
    "\n",
    "    try:\n",
    "        # Establish the connection\n",
    "        connection = psycopg2.connect(\n",
    "            host=host,\n",
    "            port=port,\n",
    "            database=db_name,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "        \n",
    "        # If the connection is successful\n",
    "        print(\"Connection to PostgreSQL DB successful\")\n",
    "        \n",
    "        # Close the connection\n",
    "        connection.close()\n",
    "    except OperationalError as e:\n",
    "        # If the connection fails\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "# Call the function to test the connection\n",
    "test_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to PostgreSQL DB successful\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import OperationalError\n",
    "\n",
    "def test_sqlalchemy_connection():\n",
    "    # Replace with your actual database credentials\n",
    "    # username = 'your_username'\n",
    "    # password = 'your_password'\n",
    "    # host = 'your_host'\n",
    "    # port = '5432'  # Default PostgreSQL port\n",
    "    # database = 'your_database'\n",
    "\n",
    "    # Create the connection string\n",
    "    connection_string = f'postgresql+psycopg2://airflow:airflow@localhost:5432/postgres'\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    try:\n",
    "        # Attempt to connect\n",
    "        with engine.connect() as connection:\n",
    "            print(\"Connection to PostgreSQL DB successful\")\n",
    "    except OperationalError as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "# Run the test\n",
    "test_sqlalchemy_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sqlalchemy.engine.base.Engine._trans_ctx'>\n"
     ]
    }
   ],
   "source": [
    "connection_string = f'postgresql://airflow:airflow@localhost:5432/postgres'\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "print(type(engine.begin()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temperature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

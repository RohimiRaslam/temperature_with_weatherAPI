{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from pandas import json_normalize\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine , inspect\n",
    "import psycopg2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('weather_api_key')\n",
    "base_url = 'http://api.weatherapi.com/v1'\n",
    "history_url = base_url + \"/history.json\"\n",
    "\n",
    "db_name = os.getenv('db_name')\n",
    "user = os.getenv('user')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "port = os.getenv('port')\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{db_name}')\n",
    "\n",
    "capitals = [\n",
    "    \"Johor Bahru\", \n",
    "    \"Alor Setar\", \n",
    "    \"Kota Bharu\", \n",
    "    \"Melaka\", \n",
    "    \"Seremban\", \n",
    "    \"Kuantan\", \n",
    "    \"George Town\", \n",
    "    \"Ipoh\", \n",
    "    \"Kangar\", \n",
    "    \"Kota Kinabalu\", \n",
    "    \"Kuching\", \n",
    "    \"Shah Alam\", \n",
    "    \"Kuala Terengganu\",\n",
    "    \"Kuala Lumpur\" \n",
    "]\n",
    "dates_string = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "dates = [(datetime.now() - timedelta(day)) for day in range(1,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_history():\n",
    "    for capital in capitals:    \n",
    "        for date in dates_string:\n",
    "            params = {'key': api_key, 'q': capital , 'dt': date}\n",
    "            r = requests.get(history_url , params=params).json()\n",
    "            df = pd.json_normalize(r)\n",
    "            hours_df = json_normalize(df['forecast.forecastday'][0][0]['hour'])\n",
    "\n",
    "            hours_df['location'] = df['location.name']\n",
    "            hours_df['region'] = df['location.region']\n",
    "            hours_df['country'] = df['location.country']\n",
    "            hours_df = hours_df.ffill(axis=0)\n",
    "            capital = re.sub(r'\\s+', '_', capital)\n",
    "            hours_df.to_sql(f\"{capital}_hourly\" , if_exists='append' , index=False , con=engine)\n",
    "\n",
    "get_hourly_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_history():\n",
    "    history_url = base_url + \"/history.json\"\n",
    "    dates = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "    hourly_dict = {}\n",
    "    \n",
    "    for date in dates:\n",
    "        for capital in capitals:\n",
    "            params = {\"key\": api_key, \"q\": capital, \"dt\": date}\n",
    "            try:\n",
    "                response = requests.get(history_url, params=params)\n",
    "                if response.status_code == 200:\n",
    "                    history_data = response.json()\n",
    "                    df = pd.json_normalize(history_data['forecast']['forecastday'][0]['hour'])\n",
    "                    # hourly = history_data['forecast']['forecastday'][0]['hour']\n",
    "                    \n",
    "                    # hourly_dict = {}\n",
    "                    \n",
    "                    # for d in hourly:\n",
    "                    #     for key, value in d.items():\n",
    "                    #         if key in hourly_dict:\n",
    "                    #             hourly_dict[key].append(value)\n",
    "                    #         else:\n",
    "                    #             hourly_dict[key] = [value]\n",
    "                    # df = pd.DataFrame(hourly_dict)\n",
    "                    # print(df.head())\n",
    "                    table_name = f\"{capital}_{date}\"\n",
    "                    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "                    # inspector = inspect(engine)\n",
    "                    # if inspector.has_table(table_name):\n",
    "                    #     print(f\"{table_name} is already existed, skipping...\")\n",
    "                    #     continue\n",
    "                    # else:\n",
    "                    #     df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "                else:\n",
    "                    print(f\"Error: Received unexpected status code {response.status_code} on {capital}\")\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "get_hourly_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "def get_hourly_history():\n",
    "    folder_path = 'hourly_data'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    history_url = base_url + \"/history.json\"\n",
    "\n",
    "    dates = [(datetime.now() - timedelta(day)).strftime(\"%Y-%m-%d\") for day in range(1,9)]\n",
    "    hourly_dict = {}\n",
    "    \n",
    "    for date in dates[:1]:\n",
    "        for capital in capitals[:1]:\n",
    "            params = {\"key\": api_key, \"q\": capital, \"dt\": date}\n",
    "            try:\n",
    "                response = requests.get(history_url, params=params)\n",
    "                if response.status_code == 200:\n",
    "                    history_data = response.json()\n",
    "\n",
    "                    hourly = history_data['forecast']['forecastday'][0]['hour']\n",
    "                    \n",
    "                    # hourly_dict = {}\n",
    "                    \n",
    "                    for d in hourly:\n",
    "                        for key, value in d.items():\n",
    "                            if key in hourly_dict:\n",
    "                                hourly_dict[key].append(value)\n",
    "                            else:\n",
    "                                hourly_dict[key] = [value]\n",
    "                    df = pd.DataFrame(hourly_dict)\n",
    "                    df = pd.json_normalize(df)\n",
    "                    print(df.head())\n",
    "\n",
    "                    # file_name = f\"{capital}_{date}\"\n",
    "                    # file_path = os.path.join(folder_path , file_name)\n",
    "\n",
    "                    # if os.path.exists(file_path):\n",
    "                    #     print(f\"{file_path} is already existed, skipping...\")\n",
    "                    #     continue\n",
    "                    # else:\n",
    "                    #     df.to_csv(file_path , index=False, header=True, encoding=None)\n",
    "                else:\n",
    "                    print(f\"Error: Received unexpected status code {response.status_code} on {capital}\")\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "get_hourly_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temperature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
